{"cells": [{"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='42d6237a-f7d6-44fb-8c26-ca2f02e831e6', project_access_token='p-08a48a87106e041736890632e780733edd1c91fc')\n", "execution_count": 1, "outputs": []}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Data Exploration: Fashion-MNIST Data\n\nThis notebook explores the [Fashion-MNIST dataset from the Data Asset Exchange](https://developer.ibm.com/exchanges/data/all/fashion-mnist/) on IBM Developer. This dataset contains 60,000 training images and 10,000 test images of fashion and clothing items, taken from 10 categories, such as shirts and dresses. Each image is in grayscale and 28 by 28 pixels in size. [Fashion-MNIST was created by Zalando Research](https://www.kaggle.com/zalando-research/fashionmnist) as a compatible replacement for the original MNIST dataset of handwritten digits. This version of the dataset has been converted to CSV to enable easier loading in common data science tools. \n\nIn this notebook, we explore the training dataset `fashion-mnist_train.csv` by:\n- Encoding label features\n- Inspecting data through visualizations\n\n\n### Table of Contents:\n* [0. Prerequisites](#section0)\n* [1. Loading the Data](#section1)\n* [2. Exploring the Data](#section2)\n  * [2.1 Display information about the dataframe](#section3)\n  * [2.2 Inspect the labels](#section4)\n* [3. Visualizing the Data](#section5)\n  * [3.1 Visualize the training images](#section6)\n  * [3.2 Visualize using Principal Component Analysis](#section7)\n  * [3.3 Visualize using t-Distributed Stochastic Neighbouring Entities](#section8)\n* [Authors](#authors)\n\n<a id=\"section0\"></a>\n### 0. Prerequisites\n\nBefore you run this notebook complete the following steps:\n- Insert a project token\n- Import required packages\n\n#### Insert a project token\n\nWhen you import this project from the Watson Studio Gallery, a token should be automatically generated and inserted at the top of this notebook as a code cell such as the one below:\n\n```python\n# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='YOUR_PROJECT_ID', project_access_token='YOUR_PROJECT_TOKEN')\npc = project.project_context\n```\n\nIf you do not see the cell above, follow these steps to enable the notebook to access the dataset from the project's resources:\n\n* Click on `More -> Insert project token` in the top-right menu section\n\n![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n\n* This should insert a cell at the top of this notebook similar to the example given above.\n\n  > If an error is displayed indicating that no project token is defined, follow [these instructions](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/token.html?audience=wdp&context=data).\n\n* Run the newly inserted cell before proceeding with the notebook execution below\n\n#### Import required packages\n\nImport and configure the required packages, including [`pandas`](https://pypi.org/project/pandas/), [`numpy`](https://pypi.org/project/numpy/), and [`matplotlib`](https://pypi.org/project/matplotlib/)."}, {"metadata": {}, "cell_type": "code", "source": "# Define required imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"section1\"></a>\n\n### 1. Loading the Data\n\nWe start by reading in the training dataset from `fashion-mnist_train.csv` into a Pandas DataFrame and previewing the first few rows."}, {"metadata": {}, "cell_type": "code", "source": "# define filename\nDATA_PATH = 'fashion-mnist_train.csv'\n\n# Create method to find filepath based on filename\ndef get_file_handle(fname):\n    # Project data path for the raw data file\n    data_path = project.get_file(fname)\n    data_path.seek(0)\n    return data_path\n\n# Using pandas to read the data \ndata_path = get_file_handle(DATA_PATH)\ndata = pd.read_csv(data_path)\n# Display the first five rows\ndata.head()", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      2       0       0       0       0       0       0       0       0   \n1      9       0       0       0       0       0       0       0       0   \n2      6       0       0       0       0       0       0       0       5   \n3      0       0       0       0       1       2       0       0       0   \n4      3       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0        30        43         0   \n3       0  ...         3         0         0         0         0         1   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel781  pixel782  pixel783  pixel784  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 785 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "The table above displays the first 5 rows of the data frame. Each row of this data frame contains information about an \"image\". The first column named `label` identifies the clothing item that is depicted in the image. The other 784 columns named `pixel` represent the image. \n\nThe mapping between the numeric value in the `label` column and the category is not included in the dataset, but defined as follows:\n- 0 - T-shirt/top <br /> \n- 1 - Trouser <br /> \n- 2 - Pullover <br /> \n- 3 - Dress <br /> \n- 4 - Coat <br /> \n- 5 - Sandal <br /> \n- 6 - Shirt <br /> \n- 7 - Sneaker <br /> \n- 8 - Bag <br /> \n- 9 - Ankle boot \n\n\nFor example, in row 0 (the first row), the numeric label value is 2, which represents a pullover.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"section2\"></a>\n\n### 2. Exploring the Data\n\nAs shown above, the mini dataset of 5 images is a matrix with 5 rows and 785 columns. Displaying it as matrix is not very informative as each cell is a pixel and as such is not human-readable. To better understand what each pixel represents, we need to convert it to a weighted form. Further investigation of the data such as shape, dimensions and labels of the data is necessary and so is the visualization. This section explores them in detail.\n\n<a id=\"section3\"></a>\n#### 2.1 Display information about the dataframe\nFirst, we collect basic information about the dataframe, such as the number of rows and the number of features."}, {"metadata": {}, "cell_type": "code", "source": "data.info()", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 60000 entries, 0 to 59999\nColumns: 785 entries, label to pixel784\ndtypes: int64(785)\nmemory usage: 359.3 MB\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The dataframe statistics indicate that there are 60,000 rows and 785 features in the training dataset. Each row represents an image that will be used during model training.\n\n<a id=\"section4\"></a>\n#### 2.2 Inspect the labels\n\nLet's count the unique number of labels in the training dataset."}, {"metadata": {}, "cell_type": "code", "source": "# count total number of unique values in the `label` column\nlen(data['label'].unique())", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "10"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Next, let's find out how many images the training dataset includes for each label."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# Number of data points under each label\ndata['label'].value_counts()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We can see that there are 6,000 images associated with each label, for a total of `10 * 6000 = 60000` pictures. This is a balanced dataset in terms of class distribution."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"section5\"></a>\n### 3.Visualizing the Data\n\nBefore we can visualize the data we need to review how it is encoded.\n\nThe 784 `pixelXXX` column values in each row contain brightness information for each pixel in the 28x28 grayscale image. The pixel brightness is stored as an 8-bit integer, ranging from 0 (typically representing black) to 255 (white). Values in between represent different shades of gray. To normalize the values, we therefore need to divide each `pixelXXX` cell by 255. You can learn more about pixel values on [this page](https://homepages.inf.ed.ac.uk/rbf/HIPR2/value.htm)."}, {"metadata": {}, "cell_type": "code", "source": "# Save the data points as 'input_data'\ninput_data = data.iloc[:,1:] / 255\n# Check the shape of the input data\nprint('Shape of the input data',input_data.shape)\n# Preview a few rows\ninput_data.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The generated `input_data` dataframe contains the label and normalized pixel values. The number of rows and columns in the dataframe has not changed. <br>\nNext, we create another dataframe named `target`, which only includes the numeric labels."}, {"metadata": {}, "cell_type": "code", "source": "# Save the label(in 0-9 format) as 'target'\ntarget = data[['label']].iloc[:, :]\n# Check the shape of the label/category\nprint('Shape of the input label', target.shape)\n# Preview a few rows\ntarget.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Since numeric labels are not that meaningful in a visualization, we'll map them to a textual representation using a lookup:\n- 0 => T-shirt/top <br /> \n- 1 => Trouser <br /> \n- 2 => Pullover <br /> \n- 3 => Dress <br /> \n- 4 => Coat <br /> \n- 5 => Sandal <br /> \n- 6 => Shirt <br /> \n- 7 => Sneaker <br /> \n- 8 => Bag <br /> \n- 9 => Ankle boot "}, {"metadata": {}, "cell_type": "code", "source": "# Manually enter the meaningful name of each label\nlabel = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We save the meaningful labels as `label` for later visualization purposes."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"section6\"></a>\n#### 3.1 Visualize the training images\n\nFirst, let's take a look at the pictures. We are using matplotlib to draw the first 30 training images in the `input_data` dataframe along with their label."}, {"metadata": {}, "cell_type": "code", "source": "# Set the figure size\nplt.figure(figsize=(10,10))\n# Show only the first 30 pictures\nfor i in range(30):\n    plt.subplot(6,5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(np.array(input_data.iloc[i, :]).reshape(28,28), cmap=plt.cm.binary)\n    plt.xlabel(label[target.label.iloc[i]])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"section7\"></a>\n#### 3.2 Visualize using Principal Component Analysis\n\n[Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA) is a statistical procedure for reducing the number of dimensions in a dataset whilst retaining most information. It is extensionally used for dimension reduction, especially for high-dimension data. \n\nBy calculating and comparing correlations between dimensions, this method provides a minimum number of variables that keep the maximum amount of variation(explanation) about how the original data is distributed. In other words, it skips the dimensions that have less explained variance and keeps the more meaningful ones.\n\nImport and configure the required packages: print_function, time, fetch_mldata, PCA, TSNE, Axes3D, sns"}, {"metadata": {}, "cell_type": "code", "source": "from __future__ import print_function\nimport time\nfrom sklearn.datasets import fetch_mldata\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn import decomposition\n%matplotlib inline\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We convert the matrix and vector to a Pandas DataFrame named `pca_df` and name the 784 pixel columns as `features` for simplicity to call multiple columns at once."}, {"metadata": {}, "cell_type": "code", "source": "# Give multiple pixel columns one name: features\nfeatures = ['pixel' + str(i+1) for i in range(input_data.shape[1]) ]\n# Create a new DataFrame df\npca_df = pd.DataFrame(input_data, columns=features)\n# Add an additional column 'y', identical with label values in data\npca_df['label'] = target['label']\n\nprint('Size of the dataframe: {}'.format(pca_df.shape))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Loop through the labels and convert them to meaningful labels. For example, from 0 to `T-shirt/top`, 1 to `Trouser`, etc."}, {"metadata": {}, "cell_type": "code", "source": "# Create an empty list which will save all meaningful labels\nresults = []\n# Loop through all label\nfor i in range(pca_df.shape[0]):\n    # Extract the label for comparison\n    if pca_df['label'][i] == 0:\n        # Save meaningful label to the results\n        results.append('T-shirt/top')\n    # Following the same code pattern as the one above\n    elif pca_df['label'][i] == 1:\n        results.append('Trouser')\n    elif pca_df['label'][i] == 2:\n        results.append('Pullover')\n    elif pca_df['label'][i] == 3:\n        results.append('Dress')\n    elif pca_df['label'][i] == 4:\n        results.append('Coat')\n    elif pca_df['label'][i] == 5:\n        results.append('Sandal')\n    elif pca_df['label'][i] == 6:\n        results.append('Shirt')\n    elif pca_df['label'][i] == 7:\n        results.append('Sneaker')\n    elif pca_df['label'][i] == 8:\n        results.append('Bag')\n    elif pca_df['label'][i] == 9:\n        results.append('Ankle boot')\n    else:\n        print(\"The dataset contains an unexpected label {}\".format(pca_df['label'][i]))\n\n# Create a new column named result which has all meaningful results        \npca_df['result'] = results", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "In this notebook we use the [Scikit-Learn implementation of PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to generate two and three dimensional plots from the original 784 dimensions (each pixel is a dimension), so we choose `n_components = 3`, the first three principal components. Let's see how much variation in the total dataset is explained by these principal components."}, {"metadata": {}, "cell_type": "code", "source": "# Set first three principle components\npca = PCA(n_components=3)\n# Fit the model with pixel columns and apply the dimensionality reduction on those columns\npca_result = pca.fit_transform(pca_df[features].values)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The `pca.explained_variance_ratio_` parameter returns a vector of the variance explained by each dimension. "}, {"metadata": {}, "cell_type": "code", "source": "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Append the three dimensional PCA values as columns to the `pca_df` dataframe, naming them `First Dimension`, `Second Dimension`, and `Third Dimension`."}, {"metadata": {}, "cell_type": "code", "source": "pca_df['First Dimension'] = pca_result[:,0]\npca_df['Second Dimension'] = pca_result[:,1] \npca_df['Third Dimension'] = pca_result[:,2]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Preview the first few rows in the `pca_df` data frame.\npca_df.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now, let's visualize the first 3 principle vectors in the principle component analysis."}, {"metadata": {}, "cell_type": "code", "source": "# Set the graph style as 'fivethirtyeight'\nplt.style.use('fivethirtyeight')\n#Set figure size\nfig, axarr = plt.subplots(1, 3, figsize=(20, 5))\n# use seaborn heatmap to visualize the first three pca components\nsns.heatmap(pca.components_[0, :].reshape(28, 28), ax=axarr[0], cmap=plt.cm.binary)\nsns.heatmap(pca.components_[1, :].reshape(28, 28), ax=axarr[1], cmap=plt.cm.binary)\nsns.heatmap(pca.components_[2, :].reshape(28, 28), ax=axarr[2], cmap=plt.cm.binary)\n# Set picture title to explained variance\naxarr[0].set_title(\n    \"{0:.2f}% Explained Variance\".format(pca.explained_variance_ratio_[0]*100), fontsize=14)\naxarr[1].set_title(\n    \"{0:.2f}% Explained Variance\".format(pca.explained_variance_ratio_[1]*100), fontsize=14)\naxarr[2].set_title(\n    \"{0:.2f}% Explained Variance\".format(pca.explained_variance_ratio_[2]*100), fontsize=14)\n# Add picture title\nplt.suptitle('3-Component PCA')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Each component is an eigenvector. The first component looks like a T-shirt and a shoe. The second component is a trouser and a pullover. The third component looks like a pullover and an ankle boot.\n\nThe first dimension explains 29% of the pixel data, the second dimension explains approximately 17%, while the third dimension explains only 6%. Each additional dimension added to the PCA explains less variance of the data. If the number of component is 784, the cumulative explained variance would be 100%. But reaching 100% explained variance requires too much work, we rather do dimension reduction and sacrifice some explained variance for the sake of efficiency. \n\nIt's crucial to pick a relatively small number of components while keep the effectiveness of the model. Let's plot the cumulative explained variance ratio for all components of the principle component analysis. To do this, we can clearly see changes of explained variance with the increase in number of components."}, {"metadata": {}, "cell_type": "code", "source": "# initializing the pca\n# Set n_components as 784 dimensions\npca = decomposition.PCA(n_components = 784)\n# Fit on training data\npca_784 = pca.fit_transform(pca_df[features].values)\n#percentage_var_explained = pca.explained_variance_ / np.sum(pca.explained_variance_);\nvar_ratios = np.cumsum(pca.explained_variance_ratio_)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Plot the PCA spectrum\nplt.figure(figsize=(6, 4))\nplt.plot(var_ratios, linewidth=2)\nplt.xlabel(\"n_components\")\nplt.ylabel(\"Cumulative_Explained_Variance\")\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "From the graph above, we see that 200 components explain approximately 95% variance and 80 components explain 90% variance. As the number of components increase, the explained variance rises to 100%, which makes sense because it is original matrix with 784 dimensions.\n\nYou can try `n_components = 10` or `n_components = 20` to further analysis."}, {"metadata": {}, "cell_type": "markdown", "source": "Plot the first two dimensions from the `pca_df` dataframe. Each color represents a label."}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "plt.figure(figsize=(16,10))\n\nsns.scatterplot(\n    x=\"First Dimension\", y=\"Second Dimension\",\n    hue = \"result\",\n    hue_order = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'],\n    palette=sns.color_palette(\"hls\", 10),\n    data=pca_df,\n    legend=\"full\",\n    alpha=0.3\n)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "From the graph above, we can see the two components can separate different categories apart to some degree, but the separation is not clear enough. Let's take a look at the three-dimensional representation."}, {"metadata": {}, "cell_type": "code", "source": "graph = plt.figure(figsize=(16,10)).gca(projection='3d')\ngraph.scatter(\n    xs=pca_df[\"First Dimension\"], \n    ys=pca_df[\"Second Dimension\"], \n    zs=pca_df[\"Third Dimension\"], \n    c=pca_df[\"label\"], \n    cmap='tab10'\n)\ngraph.set_xlabel('First Dimension')\ngraph.set_ylabel('Second Dimension')\ngraph.set_zlabel('Third Dimension')\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The three-dimensional visualization can also not sufficiently separate the categories. We need a more efficient technique."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"section8\"></a>\n####  3.3 Visualize using t-Distributed Stochastic Neighbouring Entities\n\n[t-Distributed Stochastic Neighbouring Entities](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) (t-SNE) is a machine learning algorithm that can reduce the number of dimensions more efficiently. The method is particularly good for the visualization of high-dimensional datasets. You can learn more about it in [this paper](http://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf).\n\nIn this notebook we use the [Scikit-Learn implementation of t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n\nBecause t-SNE is compute intensive we need to reduce the dimensions in this dataset. We'll do that by using a smaller subset of the images in the dataset."}, {"metadata": {}, "cell_type": "code", "source": "# Create a random generator, so to decreases potential biases in the data\nrand = np.random.permutation(pca_df.shape[0])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Pull 10000 pictures out of the sample\nN = 10000\npca_df_subset = pca_df.loc[rand[:N],:].copy()\ndata_subset = pca_df_subset[features].values\n\npca = PCA(n_components=3)\npca_result = pca.fit_transform(data_subset)\npca_df_subset['First Dimension'] = pca_result[:,0]\npca_df_subset['Second Dimension'] = pca_result[:,1] \npca_df_subset['Third Dimension'] = pca_result[:,2]\nprint('Explained variation in each principal component: {}'.format(pca.explained_variance_ratio_))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "For this dataset the first dimension explains 28.6% of the pixel data, the second dimension explains 17.9%, and the third dimension explains 6.0%. <br>\n\nRun the t-SNE machine learning algorithm, limiting the number of components to 2, which is all we need for a two-dimensional visualization. This might take a few minutes."}, {"metadata": {}, "cell_type": "code", "source": "# Keep track of time elapsed in the method\ntime_start = time.time()\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\ntsne_results = tsne.fit_transform(data_subset)\nprint('t-SNE finished! Time elapsed: {} seconds'.format(time.time()-time_start))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Display the analysis results in a two-dimensional chart."}, {"metadata": {}, "cell_type": "code", "source": "pca_df_subset['t-SNE First Dimension'] = tsne_results[:,0]\npca_df_subset['t-SNE Second Dimension'] = tsne_results[:,1]\nplt.figure(figsize=(16,10))\nsns.scatterplot(\n    x=\"t-SNE First Dimension\", y=\"t-SNE Second Dimension\",\n    hue=\"result\",\n    hue_order = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'],\n    palette=sns.color_palette(\"hls\", 10),\n    data=pca_df_subset,\n    legend=\"full\",\n    alpha=0.3\n)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "In the graph above, it shows a significant improvement in classification compared to PCA visualization. \n\nEach category is clearly clustered in its own region. For example, on the left bottom side, `Trouser` is successfully classified and differentiated from the others. Although the (light green) `Pullover`, (darker green) `Dress`, and (blue) `Shirt` are mixed in cluster as shown in the middle top part of the graph, the t-SNE is able to classify all other 7 categories. Hence, we can say this is a good classification."}, {"metadata": {}, "cell_type": "markdown", "source": "#### Next steps\n\n- Close this notebook.\n- Open the `Part 2 - ML and Model Evaluations` notebook.\n\n<a id=\"authors\"></a> \n### Authors\n\nThis notebook was created by the [Center for Open-Source Data & AI Technologies](http://codait.org).\n\nCopyright \u00a9 2019 IBM. This notebook and its source code are released under the terms of the MIT License."}, {"metadata": {}, "cell_type": "markdown", "source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}